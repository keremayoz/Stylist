{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"style_transfer.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.6"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1557307174787,"user_tz":-180,"elapsed":1133,"user":{"displayName":"Kerem Ayöz","photoUrl":"https://lh6.googleusercontent.com/-drFnBH0hny8/AAAAAAAAAAI/AAAAAAAAAVA/XJml_3wnFXQ/s64/photo.jpg","userId":"02471906260063843599"}},"id":"a7walPhzLMd2","outputId":"4c47475d-566a-47d7-e398-c3ae2e4d0080","colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EnZ_GXipLOWp","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"7bf13fa2-c64c-4a2b-ecdf-83492979edae","executionInfo":{"status":"ok","timestamp":1557307255126,"user_tz":-180,"elapsed":41024,"user":{"displayName":"Kerem Ayöz","photoUrl":"https://lh6.googleusercontent.com/-drFnBH0hny8/AAAAAAAAAAI/AAAAAAAAAVA/XJml_3wnFXQ/s64/photo.jpg","userId":"02471906260063843599"}}},"source":["!cp drive/My\\ Drive/style.jpg /content/\n","!cp drive/My\\ Drive/style2.jpg /content/\n","!cp drive/My\\ Drive/style3.jpg /content/\n","!cp drive/My\\ Drive/basee.jpg /content/"],"execution_count":13,"outputs":[{"output_type":"stream","text":["cp: cannot stat 'drive/My Drive/style.jpg': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1557307257249,"user_tz":-180,"elapsed":42389,"user":{"displayName":"Kerem Ayöz","photoUrl":"https://lh6.googleusercontent.com/-drFnBH0hny8/AAAAAAAAAAI/AAAAAAAAAVA/XJml_3wnFXQ/s64/photo.jpg","userId":"02471906260063843599"}},"id":"iPgOjHCkLOdp","outputId":"18a5e75d-f4f2-471a-83a1-b784f1f0af12","colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["!ls"],"execution_count":14,"outputs":[{"output_type":"stream","text":["basee.jpg  drive  output.jpg  sample_data  style2.jpg  style3.jpg  style.jpg\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1557307183856,"user_tz":-180,"elapsed":10131,"user":{"displayName":"Kerem Ayöz","photoUrl":"https://lh6.googleusercontent.com/-drFnBH0hny8/AAAAAAAAAAI/AAAAAAAAAVA/XJml_3wnFXQ/s64/photo.jpg","userId":"02471906260063843599"}},"id":"7hvc6vXDK-I9","outputId":"64f7e418-f13d-4784-b42f-8fc90904bc51","colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["import numpy as np\n","from keras.applications import vgg16\n","from keras import backend as K\n","from keras.preprocessing.image import load_img, img_to_array\n","from PIL import Image\n","import cv2 as cv\n","import time\n","from scipy.optimize import fmin_l_bfgs_b"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"nyyxEjimWuv4","colab_type":"text"},"source":["# **Pre-process Image**"]},{"cell_type":"code","metadata":{"id":"QTzYjGXaWuJW","colab_type":"code","colab":{}},"source":["def build_input_tensor(width, height, content_image, style_image, style_image2=None):\n","  # Add one more dimension to concatinate the images\n","  content_array = np.asarray(content_image, dtype='float32')\n","  content_array = np.expand_dims(content_array, axis=0)\n","\n","  style_array = np.asarray(style_image, dtype='float32')\n","  style_array = np.expand_dims(style_array, axis=0)\n","  \n","  style_array2 = np.asarray(style_image2, dtype='float32')\n","  style_array2 = np.expand_dims(style_array2, axis=0)\n","\n","  # Substract mean RGB values from images to make them ready to VGG16\n","  content_array[:, :, :, 0] -= 103.939\n","  content_array[:, :, :, 1] -= 116.779\n","  content_array[:, :, :, 2] -= 123.68\n","  content_array = content_array[:, :, :, ::-1]\n","\n","  style_array[:, :, :, 0] -= 103.939\n","  style_array[:, :, :, 1] -= 116.779\n","  style_array[:, :, :, 2] -= 123.68\n","  style_array = style_array[:, :, :, ::-1]\n","  \n","  # Build input tensor with Keras placeholder\n","  content_image = K.variable(content_array)\n","  style_image = K.variable(style_array)\n","  combination_image = K.placeholder((1, height, width, 3))\n","\n","  if style_image2 is not None:\n","    style_array2[:, :, :, 0] -= 103.939\n","    style_array2[:, :, :, 1] -= 116.779\n","    style_array2[:, :, :, 2] -= 123.68\n","    style_array2 = style_array2[:, :, :, ::-1]\n","    style_image2 = K.variable(style_array2)\n","    input_tensor = K.concatenate([content_image, style_image, combination_image, style_image2], axis=0)\n","  else:\n","    input_tensor = K.concatenate([content_image, style_image, combination_image], axis=0)\n","\n","  return input_tensor, combination_image"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3DKhFuFkVYRw","colab_type":"text"},"source":["# **Content Loss**"]},{"cell_type":"code","metadata":{"id":"abV5fQlMR7_c","colab_type":"code","colab":{}},"source":["def content_loss(content_layer, model, layers, content_weight):\n","  # Calculate the Content Loss, extract the activations from CNN\n","  layer_features = layers[content_layer]\n","  content_image_features = layer_features[0, :, :, :]\n","  combination_features = layer_features[2, :, :, :]\n","\n","  # Calculate the OLS error between combined image and content image\n","  content_loss = K.sum(K.square(combination_features - content_image_features))\n","  return content_weight * content_loss"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f4qBaAgfVcCr","colab_type":"text"},"source":["# **Style Loss**"]},{"cell_type":"code","metadata":{"id":"__dllORyUHit","colab_type":"code","colab":{}},"source":["def style_loss(style_layers, layers, style_weight, width, height, idx):\n","  # Layers used to calculate style loss\n","  loss = K.variable(0.)\n","  # Sum the losses we get from each layer for the style loss\n","  for layer_name in style_layers:\n","      layer_features = layers[layer_name]\n","      style_features = layer_features[idx, :, :, :]\n","      combination_features = layer_features[2, :, :, :]\n","      sl = style_loss_single(style_features, combination_features, width, height)\n","      loss += (style_weight / len(style_layers)) * sl\n","  return loss\n","\n","# Calculate Gram Matrix of given matrix (X*X^T)\n","def gram_matrix(x):\n","    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n","    gram = K.dot(features, K.transpose(features))\n","    return gram\n","\n","# Style loss calculated from single layer features\n","def style_loss_single(style, combination, width, height):\n","    style_gram = gram_matrix(style)\n","    content_gram = gram_matrix(combination)\n","    channels = 3\n","    size = height * width\n","    return K.sum(K.square(style_gram - content_gram)) / (4. * (channels ** 2) * (size ** 2))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q1QhVVe4VjPT","colab_type":"text"},"source":["# **Total Variation Loss**"]},{"cell_type":"code","metadata":{"id":"__WgvMfSVifV","colab_type":"code","colab":{}},"source":["def total_variation_loss(combination_image, total_variation_weight, width, height):\n","    a = K.square(combination_image[:, :height-1, :width-1, :] - combination_image[:, 1:, :width-1, :])\n","    b = K.square(combination_image[:, :height-1, :width-1, :] - combination_image[:, :height-1, 1:, :])\n","    return total_variation_weight * K.sum(K.pow(a + b, 1.25))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"81bZ1VSKWYPJ","colab_type":"text"},"source":["# **Optimization**"]},{"cell_type":"code","metadata":{"id":"yJGdEMTGWXog","colab_type":"code","colab":{}},"source":["def minimize_loss(loss, combination_image, width, height):\n","  # Calculate gradients of the total loss w.r.t. combined image\n","  gradients = K.gradients(loss, combination_image)\n","\n","  outputs = [loss]\n","  outputs += gradients\n","  f_outputs = K.function([combination_image], outputs)\n","  \n","  def eval_loss_and_grads(x):\n","      x = x.reshape((1, height, width, 3))\n","      outs = f_outputs([x])\n","      loss_value = outs[0]\n","      grad_values = outs[1].flatten().astype('float64')\n","      return loss_value, grad_values\n","\n","  class Evaluator(object):\n","\n","      def __init__(self):\n","          self.loss_value = None\n","          self.grads_values = None\n","\n","      def loss(self, x):\n","          assert self.loss_value is None\n","          loss_value, grad_values = eval_loss_and_grads(x)\n","          self.loss_value = loss_value\n","          self.grad_values = grad_values\n","          return self.loss_value\n","\n","      def grads(self, x):\n","          assert self.loss_value is not None\n","          grad_values = np.copy(self.grad_values)\n","          self.loss_value = None\n","          self.grad_values = None\n","          return grad_values\n","\n","  \n","  evaluator = Evaluator()\n","\n","  x = np.random.uniform(0, 255, (1, height, width, 3)) - 128.\n","\n","  iterations = 10\n","\n","  for i in range(iterations):\n","      print('Start of iteration', i+1)\n","      start_time = time.time()\n","      x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(), fprime=evaluator.grads, maxfun=20)\n","      print('Current loss value:', min_val)\n","      end_time = time.time()\n","      print('Iteration %d completed in %ds\\n' % (i+1, end_time - start_time))\n","\n","  x = x.reshape((height, width, 3))\n","  x = x[:, :, ::-1]\n","  x[:, :, 0] += 103\n","  x[:, :, 1] += 116\n","  x[:, :, 2] += 123\n","  x = np.clip(x, 0, 255).astype('uint8')\n","  return Image.fromarray(x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mfAbdwBYVd4N","colab_type":"text"},"source":["# **Style Transfer**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5oGjMUP1tl0N","colab":{}},"source":["def transfer_style(width, height, style_layers, content_layer, content, style, style2=None, content_weight = 0.025, style_weight = 5.0, total_variation_weight = 1.0):\n","  # Load content image\n","  content_image = Image.open(content)\n","  content_image = content_image.resize((width, height))\n","   \n","  # Load style image\n","  style_image = Image.open(style)\n","  style_image = style_image.resize((width, height))\n","  \n","  # If we have 2 style images\n","  if style2 is not None:\n","    # Load style image\n","    style_image2 = Image.open(style2)\n","    style_image2 = style_image2.resize((width, height))\n","    input_tensor, combination_image = build_input_tensor(width, height, content_image, style_image,style_image2)\n","  else:\n","    input_tensor, combination_image = build_input_tensor(width, height, content_image, style_image)\n","    \n","  # Create instance of pre-trained VGG16 Classifier model, do not include last layer\n","  model = vgg16.VGG16(input_tensor=input_tensor, weights=\"imagenet\", include_top=False)\n","  layers = dict([(layer.name, layer.output) for layer in model.layers])\n","  print(layers)\n","  \n","  # Calculate content loss, style loss and total variation loss\n","  loss = K.variable(0.)\n","  loss += content_loss(content_layer, model, layers, content_weight)\n","  loss += style_loss(style_layers, layers, style_weight, width, height,1)\n","  if style2 is not None:\n","    loss += style_loss(style_layers, layers, style_weight, width, height,3)\n","  loss += total_variation_loss(combination_image, total_variation_weight, width, height)\n","  \n","  # Minimize total loss by L-BFGS Algorithm\n","  result_img = minimize_loss(loss, combination_image, width, height)\n","  \n","  return result_img"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kaPAkNK0sDRB","colab_type":"text"},"source":["# Test"]},{"cell_type":"code","metadata":{"id":"GvDQdBlQR61T","colab_type":"code","outputId":"7996cada-98a1-4e86-cb8f-375679c377af","executionInfo":{"status":"ok","timestamp":1557307547118,"user_tz":-180,"elapsed":61424,"user":{"displayName":"Kerem Ayöz","photoUrl":"https://lh6.googleusercontent.com/-drFnBH0hny8/AAAAAAAAAAI/AAAAAAAAAVA/XJml_3wnFXQ/s64/photo.jpg","userId":"02471906260063843599"}},"colab":{"base_uri":"https://localhost:8080/","height":703}},"source":["'''\n","# Import Base and Style images and resize them into same dimension\n","content = 'basee.jpg'\n","style = 'style3.jpg'\n","style2 = 'style2.jpg'\n","\n","style_layers = ['block1_conv2', 'block2_conv2', 'block3_conv3', 'block4_conv3', 'block5_conv3']\n","content_layer = 'block2_conv2'\n","\n","result = transfer_style(400, 500, style_layers, content_layer, content, style, content_weight = 0.01, style_weight = 8.0, total_variation_weight = 1.0,)\n","result.save('output.jpg')\n","!cp /content/output.jpg drive/My\\ Drive/\n","result\n","'''"],"execution_count":25,"outputs":[{"output_type":"stream","text":["{'input_4': <tf.Tensor 'concat_3:0' shape=(3, 500, 400, 3) dtype=float32>, 'block1_conv1': <tf.Tensor 'block1_conv1_3/Relu:0' shape=(3, 500, 400, 64) dtype=float32>, 'block1_conv2': <tf.Tensor 'block1_conv2_3/Relu:0' shape=(3, 500, 400, 64) dtype=float32>, 'block1_pool': <tf.Tensor 'block1_pool_3/MaxPool:0' shape=(3, 250, 200, 64) dtype=float32>, 'block2_conv1': <tf.Tensor 'block2_conv1_3/Relu:0' shape=(3, 250, 200, 128) dtype=float32>, 'block2_conv2': <tf.Tensor 'block2_conv2_3/Relu:0' shape=(3, 250, 200, 128) dtype=float32>, 'block2_pool': <tf.Tensor 'block2_pool_3/MaxPool:0' shape=(3, 125, 100, 128) dtype=float32>, 'block3_conv1': <tf.Tensor 'block3_conv1_3/Relu:0' shape=(3, 125, 100, 256) dtype=float32>, 'block3_conv2': <tf.Tensor 'block3_conv2_3/Relu:0' shape=(3, 125, 100, 256) dtype=float32>, 'block3_conv3': <tf.Tensor 'block3_conv3_3/Relu:0' shape=(3, 125, 100, 256) dtype=float32>, 'block3_pool': <tf.Tensor 'block3_pool_3/MaxPool:0' shape=(3, 62, 50, 256) dtype=float32>, 'block4_conv1': <tf.Tensor 'block4_conv1_3/Relu:0' shape=(3, 62, 50, 512) dtype=float32>, 'block4_conv2': <tf.Tensor 'block4_conv2_3/Relu:0' shape=(3, 62, 50, 512) dtype=float32>, 'block4_conv3': <tf.Tensor 'block4_conv3_3/Relu:0' shape=(3, 62, 50, 512) dtype=float32>, 'block4_pool': <tf.Tensor 'block4_pool_3/MaxPool:0' shape=(3, 31, 25, 512) dtype=float32>, 'block5_conv1': <tf.Tensor 'block5_conv1_3/Relu:0' shape=(3, 31, 25, 512) dtype=float32>, 'block5_conv2': <tf.Tensor 'block5_conv2_3/Relu:0' shape=(3, 31, 25, 512) dtype=float32>, 'block5_conv3': <tf.Tensor 'block5_conv3_3/Relu:0' shape=(3, 31, 25, 512) dtype=float32>, 'block5_pool': <tf.Tensor 'block5_pool_3/MaxPool:0' shape=(3, 15, 12, 512) dtype=float32>}\n","Start of iteration 1\n","Current loss value: 75278344000.0\n","Iteration 1 completed in 6s\n","\n","Start of iteration 2\n","Current loss value: 23918780000.0\n","Iteration 2 completed in 5s\n","\n","Start of iteration 3\n","Current loss value: 16658153000.0\n","Iteration 3 completed in 5s\n","\n","Start of iteration 4\n","Current loss value: 13839111000.0\n","Iteration 4 completed in 5s\n","\n","Start of iteration 5\n","Current loss value: 12183948000.0\n","Iteration 5 completed in 5s\n","\n","Start of iteration 6\n","Current loss value: 11206377000.0\n","Iteration 6 completed in 5s\n","\n","Start of iteration 7\n","Current loss value: 10492327000.0\n","Iteration 7 completed in 5s\n","\n","Start of iteration 8\n","Current loss value: 9916363000.0\n","Iteration 8 completed in 5s\n","\n","Start of iteration 9\n","Current loss value: 9329792000.0\n","Iteration 9 completed in 5s\n","\n","Start of iteration 10\n","Current loss value: 8948883000.0\n","Iteration 10 completed in 5s\n","\n"],"name":"stdout"}]}]}